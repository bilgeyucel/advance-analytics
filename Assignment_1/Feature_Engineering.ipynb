{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Feature_Engineering.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1NAId7xVJrHY04ehnxIMtwRSRQHFUwbbf","authorship_tag":"ABX9TyNbMy5aZVoO4vJtaODDhSeG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wQh6AlSE6nvz"},"outputs":[],"source":["\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import pickle\n","import datetime as dt\n","\n","#Useful packages for building deep neural networks. \n","import tensorflow as tf \n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D,Flatten,Dense,Dropout, Reshape,MaxPooling2D,Conv2D\n","from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n","\n","#Additional library which we will use for preprocessing our image data before training our model and to provide some specific evaluation metrics.\n","import sklearn\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","source":[""],"metadata":{"id":"nFjj5kr4Wg-Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-------- KMEANS FEATURIZATION ----------"],"metadata":{"id":"Vu7b9xLTERJV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ----------------------------- K-Means Featurization (Feature engineering for machine learning - Zheng & Casari)\n","from sklearn.cluster import KMeans\n","\n","class KMeansFeaturizer:\n","  def __init__(self, k = 100, target_scale = 5.0, random_state = None):\n","    self.k = k\n","    self.target_scale = target_scale\n","    self.random_state = random_state\n","\n","  def fit(self, X, y = None):\n","    if y is None:\n","      km_model = KMeans(n_clusters=self.k,\n","                        n_init = 20,\n","                        random_state = self.random_state)\n","      km_model.fit(X)\n","      \n","      self.km_model_ = km_model\n","      self.cluster_centers_ = km_model.cluster_centers_\n","      return self\n","\n","    data_with_target = np.hstack((X, y[:,np.newaxis]*self.target_scale))\n","    km_model_pretrain = KMeans(n_clusters=self.k,\n","                               n_init=20,\n","                               random_state=self.random_state)\n","    \n","    km_model_pretrain.fit(data_with_target)\n","    km_model = KMeans(n_clusters=self.k,\n","                      init=km_model_pretrain.cluster_centers_[:,:38],\n","                      n_init=1,\n","                      max_iter=1)\n","    \n","    km_model.fit(X)\n","\n","    self.km_model = km_model\n","    self.cluster_centers_ = km_model.cluster_centers_\n","    return self\n","\n","  def transform(self, X, y=None):\n","      clusters = self.km_model.predict(X)\n","      return clusters[:,np.newaxis]\n","      \n","  def fit_transform(self, X, y=None):\n","      self.fit(X, y)\n","      return self.transform(X, y)\n","\n"],"metadata":{"id":"YK7gaBVu1Prc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LOAD DATA\n","data = pd.read_pickle('/content/drive/MyDrive/AA_assignments/Assignment 1/train_data_minmax_df3')\n","X = data.drop(columns = ['client_id', 'target'])\n","y = data['target']\n","data_with_target = data.drop(columns = ['client_id'])"],"metadata":{"id":"XQ38br5JY719"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kmf = KMeansFeaturizer(k = 4, target_scale = 10).fit(X, y)"],"metadata":{"id":"JqwIjgZhZFNv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kmf.transform(X) # Closest cluster ID for each input data point, add this as a feature"],"metadata":{"id":"EkKf9XwpZIOS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"87dyGPFOZJBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# AUTOMATED FEATURE SELECTION - Recursive feature elimination and correlation-based elimination. SOURCE: https://towardsdatascience.com/designing-a-feature-selection-pipeline-in-python-859fec4d1b12"],"metadata":{"id":"6989DJvm1PmM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.model_selection import KFold\n","from sklearn.feature_selection import RFECV\n","from boruta import BorutaPy\n","\n","class FeatureSelector:\n","    \"\"\"\n","    The FeatureSelector class implement the following feature selection \n","    methods:\n","        \n","    \n","    1. A method that removes features with very similar values. For example,\n","    a feature that contains 0 for every instance.\n","    \n","    2. A filter method that removes correlated features based on Pearson or\n","    Spearman's coefficient.\n","    \n","    3. A recursive feature elimination algorithm with cross validation.\n","    \n","    4. The Boruta method which uncovers features that are relevant to\n","    the outcome.\n","    \n","    \n","    Parameters\n","    ----------\n","    \n","    None\n","        \n","    Example\n","    -------\n","    \n","    # Define steps\n","    step1 = {'Constant Features': {'frac_constant_values': 0.90}}\n","    \n","    step2 = {'Correlated Features': {'correlation_threshold': 0.95}}\n","    \n","    step3 = {'Relevant Features': {'estimator': estimator,\n","                                   'cv': 5,\n","                                    'n_estimators': 1000,\n","                                    'max_iter': 100,\n","                                    'verbose': 50,\n","                                    'random_state': 42}}\n","    \n","    step4 = {'RFECV Features': {'estimator': estimator,\n","                                'cv': 2,\n","                                'step': 1,\n","                                'scoring': 'accuracy',\n","                                'verbose': 50,}}\n","    \n","    # Place steps in a list in the order you want them execute it\n","    steps = [step1, step2, step3, step4]\n","    \n","    # Initialize FeatureSelector()\n","    fs = FeatureSelector()\n","    \n","    # Apply feature selection methods\n","    X_selected = fs.fit(X_all_train, y_all_train, steps)\n","    \n","    \n","    Attributes\n","    ----------\n","    \n","    \n","    Author Information\n","    ------------------\n","    Frank Ceballos\n","    LinkedIn: <https://www.linkedin.com/in/frank-ceballos/>\n","    Date: January 31, 2020\n","    \"\"\"\n","    \n","    \n","    def __init__(self):\n","        self.rfecv = None\n","        self.selected_features = None\n","    \n","    \n","    def fit(self, X, y, steps = {}):\n","        \"\"\"\n","        Calls the feature selection methods in the order specified in steps and\n","        determines the selected features. \n","        \n","        \n","        Parameters\n","        ----------\n","        X : pandas dataframe\n","            A data set where each row is an observation and each column a feature.\n","        \n","        y: numpy array\n","            A numpy array containing the targets\n","            \n","        steps: list\n","            The list of steps that determines the order to apply the\n","            feature selection algorithms. Each element in this list is a dict,\n","            where key can be:\n","                            'Constant Features', \n","                            'Correlated Features'\n","                            'Relevant Features'\n","                            'RFECV Features'\n","            and the value is a dict with the parameters used to execute \n","            the feature selection method.\n","            \n","            \n","        Returns\n","        -------\n","        None\n","        \"\"\"\n","        \n","        # Determine if there are any methods that are not defined\n","        for step in steps:\n","            available_methods = ['Constant Features', 'Correlated Features', 'Relevant Features', 'RFECV Features']\n","            \n","            for key, value in step.items():\n","                if key not in available_methods:\n","                    print(f'{key} is not a valid key!')\n","                    print(f'Only these are available: {available_methods}')\n","                    print(f'Redefine the key in this dict/step: {step}')\n","                    print('Now exiting function!')\n","                    return None\n","        \n","        # Get the order the methods are going to be applied\n","        method_order = [[*step][0] for step in steps]\n","        \n","        # Get methods\n","        ordered_methods = self.get_methods(method_order)\n","        \n","        # Initiate empty list of labels to drop\n","        drop_features = []\n","        \n","        # Temporary features\n","        X_temp = X.copy()\n","        \n","        for method_label in method_order:\n","            # Get method\n","            method = ordered_methods[method_label]\n","            \n","            # Get method parameters\n","            for step in steps:\n","                if method_label in step.keys():\n","                    params = step[method_label]\n","            \n","            \n","            # Determine features to drop\n","            if method_label in ['Constant Features', 'Correlated Features']:\n","                 # Message to user\n","                print(f'Removing {method_label}')\n","                drop_features_temp = method(X_temp, **params)\n","                print(drop_features_temp)\n","                print('')\n","                \n","                # Append features to drop list\n","                drop_features = drop_features + drop_features_temp\n","                \n","                # Update feature matrix\n","                X_temp = X.drop(columns = drop_features, axis = 1)\n","            \n","            elif method_label in ['Relevant Features']:\n","                print('Selecting relevant features')\n","                relevant_features_temp = method(X_temp, y, params)\n","                print(relevant_features_temp)\n","                print('')\n","                \n","                # Update feature matrix\n","                X_temp = X[relevant_features_temp]\n","            \n","            \n","            elif method_label in ['RFECV Features']:\n","                print('Selecting RFECV features')\n","                rfecv_features_temp, feature_selector = method(X_temp, y, params)\n","                print(rfecv_features_temp)\n","                print('')\n","                \n","                # Save fitted rfecv \n","                self.rfecv = feature_selector\n","                \n","                # Update feature matrix\n","                X_temp = X[rfecv_features_temp]\n","        \n","        # Save selected features\n","        self.selected_features = list(X_temp.columns)\n","        \n","        # Message to user\n","        message = 'Done selecting features'\n","        \n","        return(print(message))\n","    \n","    def transform(self, X):\n","        \"\"\"\n","        Returns a dataframe with the selected features determine with fit()\n","        \n","        \n","        Parameters\n","        ----------\n","        X : pandas dataframe\n","            A data set where ech row is an observation and each column a feature.\n","        \n","        Returns\n","        -------\n","        X_selected : pandas dataframe\n","            Dataframe with selected features\n","        \"\"\"\n","        \n","        if self.selected_features == None:\n","            message = 'You first need to use the fit() method to determine the selected features!'\n","            return(print(message))\n","        else:\n","            # Get selected features\n","            X_selected = X[self.selected_features]\n","            return X_selected\n","            \n","        \n","        \n","    \n","    def get_methods(self, method_order):\n","        \n","        # Return feature selection methods in the order specified:\n","        ordered_methods = {}\n","        \n","        for method_label in method_order:\n","            \n","            if method_label == 'Constant Features':\n","                ordered_methods.update({method_label: constant_features})\n","            \n","            elif method_label == 'Correlated Features':\n","                ordered_methods.update({method_label: correlated_features})\n","            \n","            elif method_label == 'Relevant Features':\n","                ordered_methods.update({method_label: relevant_features})\n","                \n","            elif method_label == 'RFECV Features':\n","                ordered_methods.update({method_label: rfecv_features})\n","        \n","        return ordered_methods\n","\n","\n","def constant_features(X, frac_constant_values = 0.90):\n","    \"\"\"\n","    Identifies features that have a large fraction of constant values.\n","    \n","    \n","    Parameters\n","    ----------\n","    X : pandas dataframe\n","        A data set where each row is an observation and each column a feature.\n","        \n","    frac_constant_values: float, optional (default = 0.90)\n","        The threshold used to identify features with a large fraction of \n","        constant values.\n","        \n","    Returns\n","    -------\n","    labels: list\n","        A list with the labels identifying the features that contain a \n","        large fraction of constant values.\n","    \"\"\"\n","    \n","    # Get number of rows in X\n","    num_rows = X.shape[0]\n","    \n","    # Get column labels\n","    allLabels = X.columns.tolist()\n","    \n","    # Make a dict to store the fraction describing the value that occurs the most\n","    constant_per_feature = {label: X[label].value_counts().iloc[0]/num_rows for label in allLabels}\n","    \n","    # Determine the features that contain a fraction of missing values greater than\n","    # the specified threshold\n","    labels = [label for label in allLabels if constant_per_feature [label] > frac_constant_values]\n","    \n","    return labels\n","\n","\n","def correlated_features(X, correlation_threshold = 0.90):\n","    \"\"\"\n","    Identifies features that are highly correlated. Let's assume that if\n","    two features or more are highly correlated, we can randomly select\n","    one of them and discard the rest without losing much information.\n","    \n","    \n","    Parameters\n","    ----------\n","    X : pandas dataframe\n","        A data set where each row is an observation and each column a feature.\n","        \n","    correlation_threshold: float, optional (default = 0.90)\n","        The threshold used to identify highly correlated features.\n","        \n","    Returns\n","    -------\n","    labels: list\n","        A list with the labels identifying the features that contain a \n","        large fraction of constant values.\n","    \"\"\"\n","    \n","    # Make correlation matrix\n","    corr_matrix = X.corr(method = \"spearman\").abs()\n","    \n","    \n","    # Select upper triangle of matrix\n","    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(np.bool))\n","    \n","    # Find index of feature columns with correlation greater than correlation_threshold\n","    labels = [column for column in upper.columns if any(upper[column] >  correlation_threshold)]\n","    \n","    return labels\n","\n","\n","def relevant_features(X, y, params):\n","    \"\"\"\n","    Determines the subset of features in X that are relevant to the outcome\n","    using the Boruta algorithm. The result are cross validated. \n","        \n","    Parameters\n","    ----------\n","    X : pandas dataframe\n","        A data set where each row is an observation and each column a feature.\n","        \n","    y: numpy array\n","        A numpy array containing the targets\n","    \n","    params: dict,\n","        A dictionary containing the set of parameters use to initialize BorutaPy\n","        and determine the number of folds to use to validate the results.\n","    \n","    \n","    Examples\n","    --------\n","    # Initialize estimator\n","    estimator = RandomForestClassifier()\n","    \n","    # Define cv and BorutaPy parameters\n","     params = {'estimator': estimator,\n","               'cv': 5,\n","               'n_estimators': 1000,\n","               'max_iter': 100,\n","               'verbose': 50,\n","               'random_state': 42}\n","     \n","    # Get relevant feature labels\n","    labels = relevant_features(X = X, y = y, params = params)\n","    \n","    \n","    Returns\n","    -----\n","    labels: list\n","        A list with the labels identifying the relevant features in X.\n","    \n","    \n","    References\n","    ----------\n","    Find more details about Boruta here:\n","    https://github.com/scikit-learn-contrib/boruta_py\n","    \n","    \"\"\"\n","    \n","    # Unpack params\n","    if 'cv' in params:\n","        cv = params['cv']\n","    else:\n","        cv = 5\n","    \n","    # Remove cv key from params so we can use with BorutaPy\n","    del params['cv']\n","    \n","    # Initiate variables\n","    feature_labels = list(X.columns)\n","    selected_features_mask = np.ones(len(feature_labels))\n","    counter = 0\n","      \n","    #Get K-folds indices\n","    kf = KFold(n_splits = cv)\n","    kf.get_n_splits(X)\n","    \n","    # Initiate progress bar\n","    status.printProgressBar(counter, cv, prefix = 'Progress:', suffix = 'Complete', length = 50)\n","    \n","    # K-fold cross validation\n","    for train_index, val_index in kf.split(X):\n","        # Get train fold data\n","        X_train_fold = X.iloc[train_index, :]\n","        y_train_fold = y[train_index]\n","        \n","        # Define Boruta feature selection method\n","        feat_selector = BorutaPy(**params)\n","        \n","        # Find all relevant features\n","        feat_selector.fit(X_train_fold.values, y_train_fold)\n","        \n","        # Boruta selected feature mask\n","        selected_features_temp = feat_selector.support_\n","        \n","        # Update selected relevant features\n","        selected_features_mask = selected_features_mask*selected_features_temp\n","        \n","        # Update progress bar\n","        counter += 1\n","        status.printProgressBar(counter, cv, prefix = 'Progress:', suffix = 'Complete', length = 50)\n","    \n","    # Boruta selected feature labels\n","    labels = [feature_labels[ii] for ii in range(len(feature_labels)) if  selected_features_mask[ii] == 1]\n","    \n","    return labels\n","\n","\n","def rfecv_features(X, y, rfecv_params):\n","    \"\"\"\n","    Feature ranking with recursive feature elimination and cross-validated \n","    selection of the best number of features. Determines the minimum number\n","    of features that are needed to maxmize the model's performance. \n","    \n","    Parameters\n","    ----------\n","    X : pandas dataframe\n","        A data set where each row is an observation and each column a feature.\n","        \n","    y: numpy array\n","        A numpy array containing the targets\n","    \n","    rfecv_params: dict,\n","        A dictionary containing the set of parameters use to initialize RFECV sklearn\n","        class.\n","    \n","    \n","    Examples\n","    --------\n","    # Initialize estimator\n","    estimator = RandomForestClassifier()\n","    \n","    # Define RFECV parameters\n","    rfecv_params = {'estimator': estimator,\n","                    'cv': 2,\n","                    'step': 1,\n","                    'scoring': 'accuracy',\n","                    'verbose': 50}\n","    \n","    # Get rfecv feature labels\n","    labels = rfecv_features(X = X, y = y, rfecv_params = rfecv_params)\n","    \n","    \n","    Returns\n","    -----\n","    labels: list\n","        A list with the labels identifying the subset of features needed\n","        to maximize the model's performance.\n","    \n","    feature_selector: fitted RFECV object\n","    \n","    \n","    References\n","    ----------\n","    Find more details about Boruta here:\n","    https://github.com/scikit-learn-contrib/boruta_py\n","    \n","    \"\"\"\n","    \n","    # Initialize RFECV object\n","    feature_selector = RFECV(**rfecv_params)\n","    \n","    # Fit RFECV\n","    feature_selector.fit(X, y)\n","    \n","    # Get selected features\n","    feature_labels = X.columns\n","    \n","    # Get selected features\n","    labels = feature_labels[feature_selector.support_].tolist()\n","    \n","    return labels, feature_selector\n","\n","\n","class status:\n","    \"\"\"  Report progress of process. \"\"\"\n","    \n","    def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█'):\n","        \"\"\"\n","        Call in a loop to create terminal progress bar\n","        \n","        Parameters\n","        ----------\n","        iteration   - Required  : current iteration (Int)\n","        total       - Required  : total iterations (Int)\n","        prefix      - Optional  : prefix string (Str)\n","        suffix      - Optional  : suffix string (Str)\n","        decimals    - Optional  : positive number of decimals in percent complete (Int)\n","        length      - Optional  : character length of bar (Int)\n","        fill        - Optional  : bar fill character (Str)\n","            \n","        Examples\n","        --------\n","        from time import sleep\n","        # A List of Items\n","        items = list(range(0, 57))\n","        l = len(items)\n","        \n","        # Initial call to print 0% progress\n","        printProgressBar(0, l, prefix = 'Progress:', suffix = 'Complete', length = 50)\n","        for i, item in enumerate(items):\n","            # Do stuff...\n","            sleep(0.1)\n","            # Update Progress Bar\n","            printProgressBar(i + 1, l, prefix = 'Progress:', suffix = 'Complete', length = 50)\n","            \n","        References\n","        ----------\n","        Original Source: https://stackoverflow.com/questions/3173320/text-progress-bar-in-the-console\n","        \"\"\"\n","        \n","        \n","        percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n","        filledLength = int(length * iteration // total)\n","        bar = fill * filledLength + '-' * (length - filledLength)\n","        print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = '\\r')\n","        # Print New Line on Complete\n","        if iteration == total: \n","            print()\n"],"metadata":{"id":"Vls2G-9R1Pg-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#\"Research has shown that keeping only the most relevant features can increase performance, while keeping excess features may have a negative impact.\" (KTH Deep learning for churn prediction)\n","from numpy import mean\n","from numpy import std\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.feature_selection import RFE\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn import metrics\n","\n","\n","file = open(\"/content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/Training_Data_Cleaned/train_data_minmax_df3\",\"rb\")\n","train_df_all = pickle.load(file)\n","file.close()\n","\n","def Build_Forest_with_Feature_Engineering(df,method=\"corr\"):\n","    #method = \"corr\" first eliminates highly correlated features and then tunes the Forest's hyperparameters\n","    #method = \"rfe\" first tunes the Forest's hyperparameters with all data, and then eliminates features recursively to optimize its performance\n","\n","    # ----------------- STEP 0 - GET TRAINING AND TEST DATA ---------------------------\n","    df.sample(frac=1).reset_index(drop=True) #shuffle data & don't create a new column with original indices\n","    df.drop(\"client_id\",inplace=True,axis=1)\n","    X_train_all, y_train_all = df.loc[:, df.columns != 'target'],df.loc[:,'target']\n","\n","\n","\n","    #---------------- OPTIONAL STEP - REMOVE HIGHLY CORRELATED (AND CONSTANT) FEATURES -------------------------\n","    if(method==\"corr\"):\n","        \n","        # Define steps\n","        # step1 = {'Constant Features': {'frac_constant_values': 0.95}} #remove features of which X% of clients report the same thing\n","        step2 = {'Correlated Features': {'correlation_threshold': 0.8}} #Remove features that have more than X% correlation\n","\n","        # Place steps in a list in the order you want them execute it\n","        steps = [step2]\n","\n","        # Initialize FeatureSelector()\n","        fs = FeatureSelector()\n","\n","        # Apply feature selection methods in the order they appear in steps\n","        fs.fit(X_train_all, y_train_all, steps)\n","\n","        # Keep only the selected features\n","        X_train_all = fs.transform(X_train_all)\n","\n","  \n","    #split of training set\n","    X_train, y_train = X_train_all[0:int(0.9*len(X_train_all))],y_train_all[0:int(0.9*len(y_train_all))] #first 90% of rows\n","    X_test,y_test = X_train_all[int(0.9*len(X_train_all)):],y_train_all[int(0.9*len(y_train_all)):] #last 10%\n","\n","    print(\"Training set shape: {}\\n\".format(X_train.shape))\n","    print(\"Test set shape: {}\\n\".format(X_test.shape))\n","\n","\n","    #----------------------- STEP 2 -TUNE FOREST HYPERPARAMETERS  ------------\n","    # Initiate classifier instance\n","    estimator = RandomForestClassifier(random_state=42)\n","\n","    #get class weights\n","    classes = np.unique(y_train)\n","    class_weights_arr = sklearn.utils.class_weight.compute_class_weight(class_weight = 'balanced', classes = classes, y = y_train)\n","\n","    class_weights_dict = [{0:class_weights_arr[0]},{1:class_weights_arr[1]}] #gridsearchCV wants it as a list\n","\n","    # Define parameter grid\n","    param_grid = { 'n_estimators': [200],\n","                  'class_weight': [None, 'balanced'],\n","                  'max_features': ['auto', 'sqrt', 'log2'],\n","                  'max_depth' : [3, 4, 5, 6, 7, 8],\n","                  'min_samples_split': [0.005, 0.01, 0.05, 0.10],\n","                  'min_samples_leaf': [0.005, 0.01, 0.05, 0.10],\n","                  'criterion' :['gini', 'entropy']     ,\n","                  'n_jobs': [-1],\n","                  'class_weight': class_weights_dict\n","                  }\n","\n","    # Initialize GridSearch object\n","    gscv = GridSearchCV(estimator, param_grid, cv = 5,  n_jobs= -1, verbose = 1, scoring = 'precision' ) #Optimize for precision\n","\n","    print(\"\\nStarting the hyperparameter search for Random Forest now\")\n","    # Fit gscv\n","    gscv.fit(X_train, y_train)\n","\n","    # Get best parameters and score\n","    best_params = gscv.best_params_\n","    best_score = gscv.best_score_\n","          \n","    # Update classifier parameters\n","    estimator.set_params(**best_params)\n","\n","    # Fit classifier\n","    estimator.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred_train = estimator.predict(X_train)\n","    y_pred_test = estimator.predict(X_test)\n","\n","    # Measure performance\n","    accuracy_train = metrics.accuracy_score(y_train, y_pred_train)\n","    accuracy_test = metrics.accuracy_score(y_test, y_pred_test)\n","\n","    # Message to user\n","    print(f'The accuracy of the classifier on the train set was: {accuracy_train*100}')\n","    print(f'The accuracy of the classifier on the test set was: {accuracy_test*100}')\n","\n","\n","\n","    #---------------- OPTIONAL STEP - FIND MOST RELEVANT FEATURES BY ITERATIVELY TRAINING THE TUNED MODEL -------------------------\n","    if(method==\"rfe\"):\n","        # Initiate classifier instance\n","        estimator = RandomForestClassifier(random_state = 42)\n","\n","        # Update classifier parameters\n","        estimator.set_params(**best_params)\n","\n","        # Define steps\n","        step1 = {'RFECV Features': {'cv': 5,\n","                                    'estimator': estimator,\n","                                    'step': 1,\n","                                    'scoring': 'precision',\n","                                    'verbose': 50}}\n","\n","        # Place steps in a list in the order you want them execute it\n","        steps = [step1]\n","\n","        # Initialize FeatureSelector()\n","        fs = FeatureSelector()\n","\n","        # Apply feature selection methods in the order they appear in steps\n","        fs.fit(X_train_all, y_train_all, steps)\n","\n","        # Get selected features\n","        X_train_all = fs.transform(X_train_all)\n","\n","        #override earlier split\n","        X_train, y_train = X_train_all[0:int(0.9*len(X_train_all))],y_train_all[0:int(0.9*len(y_train_all))] #first 90% of rows\n","        X_test,y_test = X_train_all[int(0.9*len(X_train_all)):],y_train_all[int(0.9*len(y_train_all)):] #last 10%\n","\n","    print(\"Training set shape: {}\\n\".format(X_train.shape))\n","    print(\"Test set shape: {}\\n\".format(X_test.shape))\n","\n","    return X_train,y_train, X_test, y_test, estimator\n","\n","X_train, X_test, y_train, y_test, forest = Build_Forest_with_Feature_Engineering(train_df_all,method=\"corr\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q06XoDXWvkX6","outputId":"b5f7811a-9f81-402f-ca73-2eb5c000a773"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Removing Correlated Features\n","['has_homebanking', 'bal_insurance_21', 'bal_insurance_23', 'cap_life_insurance_fixed_cap', 'cap_life_insurance_decreasing_cap', 'prem_fire_car_other_insurance', 'bal_personal_loan', 'bal_mortgage_loan', 'bal_current_account', 'bal_pension_saving', 'bal_savings_account_starter', 'bal_current_account_starter', 'customer_since_bank', 'wallonia_postal_code']\n","\n","Done selecting features\n","Training set shape: (55321, 24)\n","\n","Test set shape: (6147, 24)\n","\n","\n","Starting the hyperparameter search for Random Forest now\n","Fitting 5 folds for each of 1152 candidates, totalling 5760 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:299: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"xszdOE0v1SGL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ATTEMPT TO USE FEATURETOOLS FOR FEATURE ENGINEERING - DID NOT WORK"],"metadata":{"id":"0fPraafO1SCR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import featuretools as ft\n","es = ft.EntitySet(id=\"training_data\")\n","\n","#When we do not initialize Woodwork, the first columns of dataframes added to the EntitySet will be taken as the index. Since featuretools is built for one-to-many\n","#relationships, it always matches the index of the parent dataframe to the key_column of the child. So below transformations are needed for featuretools to work\n","train_data1.rename(mapper={'client_id': 'client_id_ind'}, axis=1,inplace=True)\n","train_data1[\"client_id_col\"] = train_data1[\"client_id_ind\"]\n","train_data2.rename(mapper={'client_id': 'client_id_ind'}, axis=1,inplace=True)\n","train_data2[\"client_id_col\"] = train_data2[\"client_id_ind\"]\n","train_data3.rename(mapper={'client_id': 'client_id_ind'}, axis=1,inplace=True)\n","train_data3[\"client_id_col\"] = train_data3[\"client_id_ind\"]\n","\n","es[\"train1\"] = train_data1\n","es[\"train2\"] = train_data2\n","es[\"train3\"] = train_data3\n","\n","es = es.add_relationship(\"train2\", \"client_id_ind\", \"train1\", \"client_id_col\") #parent_df name, parent_key, child_df name, child_key (assumes one-to-many by default)\n","es = es.add_relationship(\"train3\", \"client_id_ind\", \"train2\", \"client_id_col\")\n","es.plot()\n","\n","#Extend this for time series analysis: https://featuretools.alteryx.com/en/stable/guides/time_series.html NOT SURE IF IT IS WORTH THE EFFORT FOR US"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":930},"id":"OzElzMhysJTQ","executionInfo":{"status":"ok","timestamp":1650361676892,"user_tz":-120,"elapsed":4677,"user":{"displayName":"tijl coenen","userId":"13526193257448919759"}},"outputId":"1c865478-472d-4851-d9ae-285f5e3d3aa9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/featuretools/entityset/entityset.py:1819: UserWarning: Using first column as index. To change this, specify the index parameter\n","  \"Using first column as index. \"\n"]},{"output_type":"execute_result","data":{"text/plain":["<graphviz.dot.Digraph at 0x7f4f2387a090>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: training_data Pages: 1 -->\n<svg width=\"860pt\" height=\"655pt\"\n viewBox=\"0.00 0.00 860.00 655.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 651)\">\n<title>training_data</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-651 856,-651 856,4 -4,4\"/>\n<!-- train1 -->\n<g id=\"node1\" class=\"node\">\n<title>train1</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"0,-8 0,-639 272,-639 272,-8 0,-8\"/>\n<text text-anchor=\"middle\" x=\"136\" y=\"-623.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">train1 (61468 rows)</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"0,-616 272,-616 \"/>\n<text text-anchor=\"start\" x=\"8\" y=\"-600.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">client_id_ind : Unknown; index</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-585.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">homebanking_active : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-570.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_homebanking : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-555.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_insurance_21 : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-540.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_insurance_23 : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-525.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_life_insurance_fixed_cap : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-510.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_life_insurance_decreasing_cap : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-495.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_fire_car_other_insurance : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-480.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_personal_loan : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-465.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_mortgage_loan : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-450.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_current_account : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-435.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_pension_saving : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-420.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_savings_account : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_savings_account_starter : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-390.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_current_account_starter : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-375.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_insurance_21 : Double</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-360.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_insurance_23 : Double</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-345.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cap_life_insurance_fixed_cap : Double</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-330.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cap_life_insurance_decreasing_cap : Double</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-315.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">prem_fire_car_other_insurance : Double</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-300.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_personal_loan : Double</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-285.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_mortgage_loan : Double</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-270.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_current_account : Double</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-255.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_pension_saving : Double</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-240.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_savings_account : Double</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-225.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_savings_account_starter : Double</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-210.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_current_account_starter : Double</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-195.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">visits_distinct_so : Double</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-180.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">visits_distinct_so_areas : Double</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-165.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">customer_since_all : Double</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-150.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">customer_since_bank : Double</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-135.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">customer_gender : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">customer_birth_date : Double</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-105.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">customer_self_employed : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-90.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_reported_education : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-75.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">brussels_postal_code : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-60.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">flanders_postal_code : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-45.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">wallonia_postal_code : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-30.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">other_postal_code : Integer</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">client_id_col : Unknown</text>\n</g>\n<!-- train2 -->\n<g id=\"node2\" class=\"node\">\n<title>train2</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"290,-8 290,-639 562,-639 562,-8 290,-8\"/>\n<text text-anchor=\"middle\" x=\"426\" y=\"-623.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">train2 (61468 rows)</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"290,-616 562,-616 \"/>\n<text text-anchor=\"start\" x=\"298\" y=\"-600.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">client_id_ind : Unknown; index</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-585.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">homebanking_active : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-570.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_homebanking : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-555.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_insurance_21 : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-540.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_insurance_23 : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-525.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_life_insurance_fixed_cap : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-510.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_life_insurance_decreasing_cap : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-495.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_fire_car_other_insurance : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-480.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_personal_loan : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-465.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_mortgage_loan : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-450.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_current_account : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-435.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_pension_saving : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-420.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_savings_account : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_savings_account_starter : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-390.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_current_account_starter : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-375.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_insurance_21 : Double</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-360.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_insurance_23 : Double</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-345.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cap_life_insurance_fixed_cap : Double</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-330.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cap_life_insurance_decreasing_cap : Double</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-315.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">prem_fire_car_other_insurance : Double</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-300.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_personal_loan : Double</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-285.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_mortgage_loan : Double</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-270.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_current_account : Double</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-255.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_pension_saving : Double</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-240.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_savings_account : Double</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-225.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_savings_account_starter : Double</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-210.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_current_account_starter : Double</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-195.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">visits_distinct_so : Double</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-180.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">visits_distinct_so_areas : Double</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-165.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">customer_since_all : Double</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-150.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">customer_since_bank : Double</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-135.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">customer_gender : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">customer_birth_date : Double</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-105.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">customer_self_employed : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-90.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_reported_education : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-75.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">brussels_postal_code : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-60.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">flanders_postal_code : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-45.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">wallonia_postal_code : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-30.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">other_postal_code : Integer</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">client_id_col : Unknown</text>\n</g>\n<!-- train3 -->\n<g id=\"node3\" class=\"node\">\n<title>train3</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"580,-.5 580,-646.5 852,-646.5 852,-.5 580,-.5\"/>\n<text text-anchor=\"middle\" x=\"716\" y=\"-631.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">train3 (61468 rows)</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"580,-623.5 852,-623.5 \"/>\n<text text-anchor=\"start\" x=\"588\" y=\"-608.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">client_id_ind : Unknown; index</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-593.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">homebanking_active : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-578.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_homebanking : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-563.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_insurance_21 : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-548.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_insurance_23 : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-533.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_life_insurance_fixed_cap : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_life_insurance_decreasing_cap : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-503.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_fire_car_other_insurance : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-488.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_personal_loan : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-473.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_mortgage_loan : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-458.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_current_account : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-443.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_pension_saving : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-428.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_savings_account : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-413.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_savings_account_starter : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-398.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_current_account_starter : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-383.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_insurance_21 : Double</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-368.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_insurance_23 : Double</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-353.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cap_life_insurance_fixed_cap : Double</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-338.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cap_life_insurance_decreasing_cap : Double</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-323.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">prem_fire_car_other_insurance : Double</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-308.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_personal_loan : Double</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-293.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_mortgage_loan : Double</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_current_account : Double</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-263.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_pension_saving : Double</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-248.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_savings_account : Double</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-233.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_savings_account_starter : Double</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-218.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bal_current_account_starter : Double</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-203.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">visits_distinct_so : Double</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">visits_distinct_so_areas : Double</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-173.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">customer_since_all : Double</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">customer_since_bank : Double</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-143.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">customer_gender : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-128.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">customer_birth_date : Double</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-113.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">customer_self_employed : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-98.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">target : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-83.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has_reported_education : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">brussels_postal_code : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-53.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">flanders_postal_code : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-38.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">wallonia_postal_code : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-23.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">other_postal_code : Integer</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">client_id_col : Unknown</text>\n</g>\n</g>\n</svg>\n"},"metadata":{},"execution_count":30}]}]}