{"cells":[{"cell_type":"code","execution_count":null,"id":"6846de35","metadata":{"id":"6846de35"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import pickle\n","import datetime as dt\n","\n","#Useful packages for building deep neural networks. \n","import tensorflow as tf \n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D,Flatten,Dense,Dropout, Reshape,MaxPooling2D,Conv2D, LSTM\n","from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n","\n","#Additional library which we will use for preprocessing our image data before training our model and to provide some specific evaluation metrics.\n","import sklearn\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","source":["#LOAD THE CLEANED DATASET\n","import pickle\n","file = open(\"/content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/Test_Data_Cleaned/test_data_minmax_df3\",\"rb\")\n","test_df3 = pickle.load(file)\n","file.close()\n"],"metadata":{"id":"sVV02Y16xejb"},"id":"sVV02Y16xejb","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--------- Helper Functions -----------------\n","import random\n","from sklearn.utils import shuffle\n","\n","#SORT DFs FIRST, ASSURE THAT CUSTOMERS LOCATED AT SAME INDICES ACROSS TABLES\n","def undersample(arr,labels,amount):\n","  churn_ratio_old = (labels==1).sum()/(len(labels))\n","\n","  ind_non_churners = list(np.where(labels==0)[0])\n","  print(len(ind_non_churners))\n","  ind_to_drop = random.sample(ind_non_churners,amount)\n","  arr = np.delete(arr,ind_to_drop,axis=0)\n","  labels = np.delete(labels,ind_to_drop)\n","  print(arr.shape, labels.shape)\n","\n","  churn_ratio_new = (labels==1).sum()/(len(labels))\n","  print('old churn ratio vs new churn ratio: {} vs. {}'.format(churn_ratio_old,churn_ratio_new))\n","  return arr, labels\n","\n","\n","def oversample(arr,labels,times): #time = number of times the churners should be re-added to the dataframe \n","   churn_ratio_old = (labels==1).sum()/(len(labels))\n","   ind_churners = list(np.where(labels==1)[0])\n","   print(len(ind_churners))\n","   print(ind_churners)\n","   for i in range(times):\n","     tmp_train = arr[ind_churners]\n","     tmp_labels = labels[ind_churners]\n","     arr = np.concatenate([arr,tmp_train],axis=0) #Add churners to the end\n","     labels = np.concatenate([labels,tmp_labels])\n","\n","   print(arr.shape,labels.shape)\n","   #Shuffle everything\n","   arr,labels = shuffle(arr,labels,random_state=42)\n","   return arr,labels"],"metadata":{"id":"iPxlmtjIWa14"},"id":"iPxlmtjIWa14","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------- TRANSFORM DATA TO BE IN CORRECT FORMAT FOR LSTM  ------------------------\n","\n","def lsmt_transform(filename_load,save_suffix):\n","  #Load dataset month 1\n","  file = open(\"/content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/Training_Data_Cleaned/{}_1\".format(filename_load),\"rb\")\n","  train_df1 = pickle.load(file)\n","  file.close()\n","\n","  train_df1.sort_values(by=['client_id'],inplace=True) #Sort values for consistent row positions per customer across dataframes\n","  train_df1.drop([\"client_id\"],inplace=True,axis=1) #Drop client id\n","  train_df1.reset_index(drop=True,inplace=True)\n","\n","  #Load dataset month 2\n","  file = open(\"/content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/Training_Data_Cleaned/{}_2\".format(filename_load),\"rb\")\n","  train_df2 = pickle.load(file)\n","  file.close()\n","\n","  train_df2.sort_values(by=['client_id'],inplace=True) #Sort values for consistent row positions per customer across dataframes\n","  train_df2.drop([\"client_id\"],inplace=True,axis=1) #Drop client id\n","  train_df2.reset_index(drop=True,inplace=True)\n","\n","\n","  #Load dataset month 3\n","  file = open(\"/content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/Training_Data_Cleaned/{}_3\".format(filename_load),\"rb\")\n","  train_df3 = pickle.load(file)\n","  file.close()\n","\n","  train_df3.sort_values(by=['client_id'],inplace=True) #Sort values for consistent row positions per customer across dataframes\n","  y_train_lstm = train_df3[\"target\"]\n","  train_df3.drop([\"client_id\",\"target\"],inplace=True,axis=1) #Drop client id\n","  train_df3.reset_index(drop=True,inplace=True)\n","\n","\n","  #create arrays to accumulate datasets\n","  X_train_lstm = np.empty((train_df1.shape[0],3,train_df1.shape[1]),dtype='float')\n","\n","  #ACCUMULATE TRAINING DF\n","  #Add all observations from train_df1\n","  for x in range(len(train_df1)):\n","    X_train_lstm[x][0] = train_df1.iloc[x,:]\n","    #Add all observations from train_df2\n","  for x in range(len(train_df2)):\n","    X_train_lstm[x][1] = train_df2.iloc[x,:]\n","  #Add all observations from train_df3\n","  for x in range(len(train_df3)):\n","    X_train_lstm[x][2] = train_df3.iloc[x,:]\n","\n","  print(X_train_lstm.shape)\n","\n","\n","  \n","  file = open(\"/content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/LSTM_DATA/X_train_lstm_robust_{}\".format(save_suffix),'wb')\n","  pickle.dump(X_train_lstm, file)\n","  file.close()\n","  file = open(\"/content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/LSTM_DATA/y_train_lstm_robust_{}\".format(save_suffix),'wb')\n","  pickle.dump(y_train_lstm, file)\n","  file.close()\n","\n","\n","lsmt_transform(\"train_data_robust\",\"robust\")\n","\n"],"metadata":{"id":"7LPlkzltxdhz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652094673520,"user_tz":-120,"elapsed":39323,"user":{"displayName":"tijl coenen","userId":"13526193257448919759"}},"outputId":"56467c0d-bb6b-4f9e-aaa6-195cb78c5d55"},"id":"7LPlkzltxdhz","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(61468, 3, 38)\n"]}]},{"cell_type":"code","source":["#--------------- CREATE CLASS DICTIONARY + SPLIT TEST SET -----------------\n","# IF DATA HAS ALREADY BEEN SAVED,JUST LOAD IT\n","file = open(\"/content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/LSTM_DATA/X_train_lstm_robust_robust\",'rb')\n","X_train_lstm = pickle.load(file)\n","file.close()\n","file = open(\"/content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/LSTM_DATA/y_train_lstm_robust_robust\",'rb')\n","y_train_lstm = np.array(pickle.load(file))\n","file.close()\n","\n","\n","\n","# Apply sampling for class balancing\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","# oversample = SMOTE(sampling_strategy=0.2) #Generate new examples\n","# X_train_lstm,y_train_lstm = oversample.fit_resample(X_train_lstm, y_train_lstm)\n","#undersample\n","#oversample\n","\n","X_train_lstm,y_train_lstm = oversample(X_train_lstm,y_train_lstm,times=2)\n","X_train_lstm,y_train_lstm = undersample(X_train_lstm,y_train_lstm,20000)\n","\n","\n","\n","\n","# Split of validation set\n","val_indices = np.random.choice(a = len(X_train_lstm), size = int(len(X_train_lstm)*0.1))\n","X_val_lstm, y_val_lstm = X_train_lstm[val_indices], y_train_lstm[val_indices]\n","X_train_lstm, y_train_lstm = np.delete(arr=X_train_lstm,obj=val_indices,axis=0), np.delete(arr=y_train_lstm,obj=val_indices,axis=0)\n","\n","#create class weights dictionary\n","classes = np.unique(y_train_lstm,return_counts=True)[0]\n","class_weights_arr = sklearn.utils.class_weight.compute_class_weight(class_weight = 'balanced', classes = classes, y = y_train_lstm)\n","print(class_weights_arr)\n","class_weights_dict = {} #input to model.fit requires dictionary\n","for i in classes:\n","  class_weights_dict[int(i)] = class_weights_arr[int(i)]\n","print(\"target attribute weights to handle class imbalance:{}\".format(class_weights_dict))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tj0qMwMtXqCt","executionInfo":{"status":"ok","timestamp":1652101155186,"user_tz":-120,"elapsed":405,"user":{"displayName":"tijl coenen","userId":"13526193257448919759"}},"outputId":"399b252c-aab9-442f-e630-ec8c0ec5a79e"},"id":"Tj0qMwMtXqCt","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1824\n","[1, 9, 22, 53, 78, 92, 106, 151, 180, 190, 225, 237, 331, 335, 337, 437, 465, 510, 514, 523, 532, 537, 568, 579, 596, 626, 639, 645, 648, 658, 788, 819, 820, 848, 891, 921, 968, 998, 1014, 1025, 1071, 1082, 1083, 1123, 1249, 1255, 1343, 1369, 1432, 1467, 1491, 1505, 1510, 1535, 1536, 1578, 1617, 1640, 1645, 1674, 1677, 1682, 1712, 1783, 1810, 1819, 1849, 1886, 1936, 1976, 2033, 2059, 2071, 2188, 2242, 2262, 2279, 2313, 2317, 2345, 2347, 2382, 2396, 2418, 2454, 2455, 2457, 2461, 2463, 2473, 2529, 2572, 2628, 2651, 2659, 2671, 2678, 2703, 2747, 2768, 2814, 2818, 2861, 2886, 2893, 2989, 3015, 3038, 3063, 3105, 3114, 3141, 3149, 3276, 3283, 3382, 3412, 3479, 3536, 3552, 3623, 3656, 3790, 3849, 3955, 3982, 4018, 4025, 4191, 4225, 4240, 4254, 4317, 4336, 4418, 4470, 4504, 4534, 4615, 4628, 4681, 4745, 4774, 4786, 4877, 4888, 4918, 4923, 4954, 4973, 4999, 5060, 5091, 5187, 5262, 5266, 5285, 5335, 5353, 5411, 5423, 5474, 5548, 5600, 5601, 5626, 5655, 5709, 5724, 5763, 5840, 5844, 5893, 5908, 6036, 6057, 6061, 6083, 6091, 6112, 6113, 6116, 6129, 6152, 6164, 6191, 6234, 6239, 6247, 6310, 6346, 6380, 6424, 6426, 6445, 6476, 6490, 6504, 6658, 6663, 6820, 6898, 6947, 6948, 6977, 7010, 7066, 7089, 7128, 7131, 7287, 7295, 7302, 7329, 7361, 7420, 7427, 7441, 7463, 7567, 7623, 7642, 7643, 7649, 7684, 7685, 7789, 7875, 7914, 7946, 8045, 8146, 8226, 8229, 8237, 8253, 8342, 8394, 8425, 8437, 8448, 8468, 8479, 8558, 8587, 8735, 8736, 8807, 8887, 8889, 8897, 8930, 8945, 8958, 8960, 9003, 9058, 9076, 9100, 9117, 9120, 9141, 9218, 9316, 9317, 9365, 9373, 9460, 9510, 9527, 9531, 9558, 9595, 9600, 9618, 9665, 9763, 9779, 9810, 9868, 9887, 9912, 9983, 10075, 10100, 10123, 10139, 10158, 10183, 10246, 10254, 10342, 10355, 10503, 10619, 10623, 10640, 10680, 10683, 10694, 10722, 10751, 10802, 10837, 10867, 10879, 10903, 10919, 10927, 10980, 10992, 11016, 11071, 11097, 11112, 11125, 11148, 11239, 11280, 11297, 11384, 11483, 11571, 11588, 11610, 11735, 11821, 11845, 11865, 11885, 11934, 12015, 12026, 12051, 12074, 12080, 12092, 12095, 12103, 12114, 12138, 12154, 12168, 12175, 12207, 12226, 12261, 12262, 12267, 12314, 12321, 12327, 12343, 12390, 12392, 12420, 12444, 12453, 12503, 12528, 12552, 12588, 12637, 12650, 12715, 12726, 12782, 12851, 12924, 12925, 13054, 13071, 13076, 13083, 13128, 13187, 13203, 13224, 13226, 13228, 13313, 13320, 13345, 13383, 13406, 13446, 13451, 13467, 13474, 13508, 13549, 13562, 13603, 13621, 13670, 13683, 13778, 13801, 13813, 13831, 13843, 13905, 13938, 13971, 14101, 14140, 14184, 14319, 14360, 14381, 14417, 14418, 14423, 14433, 14449, 14509, 14532, 14540, 14674, 14686, 14692, 14694, 14849, 14856, 14933, 14943, 14954, 14956, 14969, 14989, 14997, 15053, 15131, 15176, 15206, 15346, 15353, 15371, 15429, 15459, 15467, 15511, 15558, 15584, 15608, 15614, 15616, 15623, 15719, 15723, 15771, 15782, 15803, 15810, 15817, 15835, 15887, 15930, 15972, 15987, 15996, 16028, 16075, 16091, 16134, 16137, 16158, 16176, 16180, 16200, 16372, 16379, 16380, 16382, 16386, 16458, 16462, 16473, 16525, 16542, 16613, 16641, 16646, 16682, 16684, 16758, 16772, 16863, 16864, 16870, 16894, 16933, 16944, 16952, 17081, 17088, 17097, 17118, 17146, 17155, 17182, 17217, 17223, 17266, 17273, 17280, 17296, 17369, 17415, 17482, 17491, 17540, 17584, 17637, 17696, 17722, 17755, 17778, 17921, 18024, 18146, 18160, 18174, 18296, 18336, 18354, 18356, 18409, 18428, 18435, 18509, 18527, 18585, 18588, 18623, 18685, 18689, 18710, 18794, 18823, 18910, 18963, 19026, 19027, 19059, 19093, 19205, 19269, 19381, 19387, 19406, 19421, 19506, 19557, 19629, 19660, 19735, 19736, 19750, 19782, 19882, 19889, 19917, 19996, 20011, 20038, 20042, 20052, 20061, 20088, 20094, 20122, 20129, 20145, 20172, 20205, 20230, 20261, 20263, 20276, 20302, 20367, 20428, 20449, 20457, 20474, 20568, 20582, 20626, 20645, 20650, 20652, 20672, 20690, 20750, 20776, 20845, 20855, 20862, 20923, 21027, 21047, 21075, 21088, 21108, 21162, 21194, 21220, 21282, 21289, 21319, 21367, 21387, 21421, 21427, 21463, 21494, 21499, 21560, 21568, 21577, 21600, 21624, 21713, 21730, 21741, 21754, 21761, 21785, 21795, 21850, 21882, 21916, 21933, 22069, 22072, 22118, 22154, 22227, 22250, 22258, 22268, 22270, 22309, 22310, 22339, 22357, 22364, 22439, 22441, 22449, 22470, 22490, 22539, 22768, 22795, 22808, 22831, 22842, 22905, 22945, 22952, 22985, 22989, 23020, 23027, 23071, 23073, 23088, 23133, 23143, 23183, 23250, 23273, 23334, 23371, 23373, 23465, 23470, 23587, 23604, 23631, 23673, 23718, 23758, 23791, 23804, 23834, 23844, 23853, 23869, 23945, 23950, 23983, 23998, 24020, 24057, 24064, 24099, 24114, 24150, 24332, 24411, 24438, 24492, 24611, 24620, 24693, 24764, 24945, 25000, 25025, 25071, 25093, 25095, 25096, 25146, 25186, 25202, 25227, 25232, 25259, 25284, 25329, 25429, 25442, 25450, 25466, 25560, 25567, 25570, 25600, 25614, 25615, 25651, 25718, 25756, 25768, 25794, 25801, 25805, 25878, 25912, 25917, 25963, 25964, 25978, 25995, 26032, 26043, 26049, 26069, 26100, 26154, 26159, 26225, 26228, 26236, 26257, 26263, 26271, 26356, 26375, 26384, 26394, 26397, 26418, 26453, 26463, 26475, 26493, 26499, 26512, 26518, 26531, 26592, 26603, 26608, 26695, 26722, 26735, 26777, 26805, 26829, 26835, 26849, 26899, 26927, 26975, 27036, 27056, 27073, 27124, 27144, 27171, 27211, 27237, 27243, 27303, 27311, 27407, 27434, 27499, 27508, 27510, 27520, 27605, 27626, 27681, 27790, 27833, 27839, 27858, 27905, 27999, 28079, 28115, 28137, 28138, 28161, 28187, 28204, 28234, 28239, 28244, 28280, 28366, 28384, 28421, 28428, 28441, 28443, 28462, 28488, 28497, 28534, 28539, 28551, 28554, 28556, 28572, 28603, 28618, 28657, 28693, 28699, 28731, 28835, 28849, 28851, 28853, 28880, 28950, 28957, 28967, 28978, 28984, 28997, 29071, 29105, 29123, 29149, 29219, 29221, 29273, 29387, 29407, 29437, 29449, 29455, 29496, 29524, 29535, 29554, 29575, 29701, 29705, 29740, 29744, 29782, 29820, 29827, 29883, 29901, 29996, 30040, 30115, 30133, 30148, 30162, 30173, 30182, 30185, 30219, 30295, 30315, 30366, 30423, 30425, 30445, 30454, 30468, 30515, 30610, 30629, 30632, 30650, 30690, 30704, 30717, 30722, 30726, 30742, 30766, 30811, 30897, 30966, 31096, 31137, 31160, 31224, 31291, 31302, 31316, 31369, 31405, 31455, 31468, 31525, 31531, 31540, 31570, 31581, 31634, 31722, 31727, 31771, 31807, 31817, 31818, 31820, 31890, 31903, 31905, 31911, 31959, 31967, 31971, 31997, 32040, 32100, 32259, 32281, 32306, 32326, 32377, 32414, 32417, 32436, 32489, 32502, 32527, 32595, 32654, 32696, 32699, 32707, 32713, 32729, 32737, 32780, 32815, 32827, 32846, 32848, 32861, 32875, 32876, 32880, 32885, 32908, 32965, 32992, 33001, 33091, 33132, 33147, 33157, 33159, 33173, 33180, 33283, 33291, 33337, 33383, 33414, 33460, 33549, 33556, 33570, 33585, 33603, 33627, 33638, 33640, 33661, 33683, 33716, 33754, 33756, 33758, 33830, 33880, 33881, 33898, 33914, 33922, 33939, 33970, 34003, 34005, 34019, 34053, 34058, 34131, 34142, 34176, 34203, 34275, 34281, 34334, 34365, 34381, 34389, 34394, 34471, 34483, 34493, 34575, 34590, 34621, 34622, 34623, 34667, 34669, 34736, 34755, 34766, 34778, 34781, 34810, 34872, 34875, 34967, 34985, 35007, 35054, 35057, 35089, 35110, 35150, 35193, 35194, 35296, 35341, 35443, 35480, 35539, 35571, 35590, 35628, 35711, 35742, 35781, 35804, 35809, 35826, 35829, 35861, 35863, 35870, 35963, 35972, 35974, 36047, 36091, 36103, 36132, 36136, 36231, 36235, 36379, 36431, 36443, 36460, 36483, 36490, 36495, 36599, 36656, 36722, 36730, 36759, 36782, 36809, 36810, 36831, 36834, 36854, 36967, 36992, 37029, 37037, 37052, 37062, 37102, 37133, 37195, 37338, 37381, 37399, 37425, 37429, 37457, 37507, 37580, 37593, 37596, 37606, 37616, 37631, 37650, 37698, 37787, 37797, 37886, 37913, 37930, 37965, 37966, 37997, 38021, 38032, 38063, 38090, 38127, 38162, 38197, 38252, 38260, 38287, 38409, 38418, 38486, 38562, 38566, 38579, 38588, 38616, 38623, 38660, 38730, 38801, 38837, 38992, 39048, 39098, 39104, 39157, 39234, 39289, 39354, 39382, 39397, 39407, 39415, 39479, 39502, 39511, 39587, 39592, 39628, 39629, 39630, 39736, 39776, 39785, 39787, 39808, 39865, 39878, 39885, 39956, 39980, 39989, 39994, 40036, 40041, 40073, 40102, 40117, 40127, 40175, 40179, 40242, 40252, 40257, 40285, 40293, 40327, 40339, 40404, 40423, 40523, 40526, 40670, 40671, 40836, 40880, 40902, 40923, 40951, 41068, 41109, 41119, 41158, 41202, 41219, 41225, 41270, 41276, 41286, 41293, 41348, 41350, 41359, 41371, 41393, 41418, 41451, 41479, 41522, 41552, 41565, 41569, 41598, 41615, 41624, 41689, 41706, 41745, 41765, 41783, 41820, 41865, 41875, 41908, 41946, 42030, 42060, 42070, 42093, 42103, 42113, 42119, 42140, 42153, 42161, 42222, 42234, 42349, 42372, 42400, 42441, 42511, 42514, 42523, 42546, 42583, 42585, 42623, 42628, 42639, 42763, 42838, 42849, 42864, 42891, 42905, 42958, 42981, 43034, 43140, 43175, 43306, 43315, 43329, 43369, 43380, 43391, 43419, 43458, 43484, 43495, 43562, 43645, 43670, 43705, 43730, 43752, 43782, 43842, 44089, 44095, 44188, 44195, 44207, 44230, 44245, 44256, 44265, 44293, 44295, 44314, 44340, 44353, 44374, 44389, 44464, 44495, 44589, 44687, 44726, 44754, 44834, 44877, 44947, 44949, 44976, 45015, 45101, 45105, 45106, 45115, 45161, 45180, 45206, 45328, 45335, 45366, 45369, 45464, 45493, 45496, 45579, 45644, 45744, 45757, 45773, 45791, 45795, 45801, 45881, 45884, 45890, 45913, 45954, 45967, 45981, 46025, 46129, 46142, 46175, 46235, 46247, 46262, 46274, 46275, 46302, 46359, 46397, 46421, 46517, 46521, 46639, 46661, 46666, 46685, 46742, 46744, 46749, 46758, 46780, 46789, 46799, 46827, 46866, 46914, 46967, 46980, 47018, 47026, 47038, 47071, 47087, 47097, 47129, 47141, 47189, 47201, 47256, 47309, 47325, 47363, 47380, 47387, 47407, 47441, 47475, 47508, 47510, 47525, 47553, 47603, 47647, 47686, 47696, 47767, 47774, 47830, 47849, 47860, 47889, 47983, 48073, 48106, 48140, 48141, 48170, 48210, 48221, 48242, 48324, 48466, 48469, 48476, 48479, 48528, 48547, 48548, 48550, 48567, 48581, 48667, 48693, 48714, 48720, 48727, 48729, 48733, 48758, 48759, 48776, 48803, 48804, 48814, 48859, 48866, 48877, 48946, 49008, 49072, 49077, 49082, 49096, 49111, 49141, 49160, 49179, 49220, 49243, 49285, 49333, 49458, 49482, 49565, 49571, 49574, 49619, 49661, 49684, 49700, 49713, 49715, 49747, 49806, 49851, 49860, 49906, 49979, 50002, 50042, 50061, 50104, 50150, 50154, 50192, 50198, 50205, 50214, 50231, 50289, 50294, 50299, 50313, 50361, 50393, 50403, 50483, 50506, 50510, 50624, 50637, 50645, 50655, 50665, 50682, 50688, 50794, 50846, 50926, 50938, 50942, 50994, 51004, 51050, 51052, 51069, 51070, 51075, 51080, 51098, 51116, 51123, 51149, 51188, 51208, 51274, 51345, 51373, 51429, 51438, 51461, 51519, 51535, 51547, 51607, 51700, 51737, 51742, 51804, 51810, 51812, 51829, 51918, 52044, 52123, 52129, 52185, 52236, 52253, 52258, 52305, 52334, 52368, 52374, 52382, 52385, 52474, 52480, 52483, 52485, 52561, 52585, 52616, 52625, 52640, 52642, 52656, 52679, 52694, 52769, 52790, 52900, 52908, 52915, 52917, 53223, 53226, 53333, 53371, 53449, 53516, 53553, 53566, 53584, 53592, 53630, 53658, 53764, 53789, 53832, 53852, 53862, 53984, 53991, 53996, 54014, 54048, 54054, 54062, 54069, 54145, 54231, 54268, 54330, 54358, 54371, 54373, 54375, 54430, 54481, 54573, 54609, 54614, 54623, 54638, 54664, 54715, 54717, 54816, 54852, 54882, 54929, 54949, 55070, 55090, 55105, 55116, 55137, 55255, 55340, 55369, 55403, 55451, 55455, 55516, 55517, 55530, 55548, 55671, 55680, 55819, 55825, 55855, 55863, 55883, 55917, 55918, 55920, 55943, 55947, 55969, 56005, 56014, 56061, 56148, 56156, 56186, 56203, 56290, 56321, 56331, 56389, 56411, 56437, 56492, 56534, 56561, 56564, 56567, 56584, 56595, 56602, 56607, 56678, 56700, 56756, 56778, 56782, 56818, 57009, 57026, 57292, 57327, 57375, 57459, 57481, 57529, 57545, 57547, 57557, 57571, 57585, 57617, 57624, 57635, 57651, 57688, 57690, 57725, 57739, 57767, 57804, 57814, 57893, 57896, 57909, 57958, 57971, 58029, 58090, 58122, 58206, 58242, 58262, 58293, 58328, 58332, 58359, 58406, 58412, 58453, 58517, 58622, 58639, 58668, 58707, 58744, 58749, 58756, 58789, 58816, 58881, 58885, 58982, 59059, 59084, 59103, 59113, 59140, 59147, 59193, 59202, 59236, 59336, 59357, 59382, 59523, 59562, 59634, 59665, 59683, 59690, 59735, 59753, 59766, 59786, 59832, 59857, 59858, 59889, 59914, 59918, 59968, 59977, 60079, 60082, 60084, 60085, 60103, 60110, 60122, 60258, 60433, 60472, 60558, 60602, 60699, 60846, 60882, 60940, 61020, 61043, 61047, 61062, 61065, 61097, 61113, 61128, 61142, 61153, 61160, 61161, 61166, 61241, 61275, 61317, 61321, 61329, 61352, 61408, 61444, 61448]\n","(65116, 3, 38) (65116,)\n","59644\n","(45116, 3, 38) (45116,)\n","old churn ratio vs new churn ratio: 0.08403464586276799 vs. 0.12128734816916394\n","[0.56873833 4.13698075]\n","target attribute weights to handle class imbalance:{0: 0.5687383346797783, 1: 4.136980749746707}\n"]}]},{"cell_type":"code","source":["#CUSTOM LOSS FUNCTIONS\n","#Keras\n","ALPHA = 0.8\n","BETA = 0.2\n","\n","def TverskyLoss(targets, inputs, alpha=ALPHA, beta=BETA, smooth=1e-6):\n","        \n","        #flatten label and prediction tensors\n","        inputs = tf.cast(K.flatten(inputs), dtype=\"float32\")\n","        targets =tf.cast(K.flatten(targets), dtype=\"float32\")\n","        \n","        #True Positives, False Positives & False Negatives\n","        TP = K.sum((inputs * targets))\n","        FP = K.sum(((1-targets) * inputs))\n","        FN = K.sum((targets * (1-inputs)))\n","       \n","        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n","        \n","        return 1 - Tversky\n","\n","def DiceLoss(targets, inputs, smooth=1e-6):\n","    \n","    #flatten label and prediction tensors\n","    inputs = K.flatten(inputs)\n","    targets = K.flatten(targets)\n","    \n","    intersection = K.sum(K.dot(targets, inputs))\n","    dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n","    return 1 - dice\n","  "],"metadata":{"id":"J9-6klCa0wNI"},"id":"J9-6klCa0wNI","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.layers import Input\n","from tensorflow.keras.models import Model\n","import tensorflow.keras.backend as K\n","\n","from keras.layers import GlobalMaxPooling1D,GlobalAveragePooling1D,MaxPooling2D,AveragePooling2D, Flatten\n","def build_lstm(input_shape):\n","  x_input = Input(input_shape)\n","  x = x_input\n","  x = Conv1D(filters = 256, kernel_size=3, activation = 'relu')(x)\n","  x = Dropout(0.3)(x)\n","  x = Conv1D(filters = 128, kernel_size=1, activation = 'linear')(x)\n","  x = Dropout(0.3)(x)\n","  # x = Conv1D(filters = 32, kernel_size=1, activation = 'linear')(x)\n","  # x = Dropout(0.3)(x)\n","  # x = LSTM(160, activation='relu')(x)\n","  # x = Dropout(0.3)(x)\n","  x = Flatten(x)\n","  x = Dense(units= 256, activation = 'relu')(x)\n","  x = Dropout(0.3)(x)  \n","  x = Dense(units= 256, activation = 'relu')(x)\n","  x = Dropout(0.3)(x) \n","  x = Dense(units= 128, activation = 'relu')(x)\n","  x = Dropout(0.3)(x)\n","  x = Dense(units= 64, activation = 'relu')(x)\n","  x = Dense(1, activation='sigmoid')(x)\n","\n","  # Create model\n","  model = Model(inputs = x_input, outputs = x)\n","\n","  return model\n","\n","# initialize optimizer \n","adm = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n","\n","\n","# initialize and train model\n","model = build_lstm((3,38)) \n","model.compile(loss=TverskyLoss, optimizer=adm, metrics=[tf.keras.metrics.AUC(),'accuracy'])\n","model.summary()\n","\n","\n","model.fit(X_train_lstm, \n","          y_train_lstm, \n","          validation_data=(X_val_lstm,y_val_lstm),\n","          epochs=20, \n","          batch_size=32,\n","          class_weight = class_weights_dict\n","          )\n","\n","#Show predictive performance - ADD AUC ASS WELL!\n","predictions_proba = model.predict(X_val_lstm)\n","predictions = []\n","for x in predictions_proba:\n","  if x>0.5:\n","    predictions.append(1)\n","  else:\n","    predictions.append(0)\n","\n","#AUC Curve is desirable here to evaluate the effect of different cut-off values for the predictions\n","\n","print('Overall classification report:') \n","print(classification_report(y_val_lstm,predictions))\n","\n","print('\\nConfusion matrix:')\n","sklearn.metrics.ConfusionMatrixDisplay.from_predictions(y_val_lstm, predictions, normalize = 'true') \n","plt.show() "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vlb4MiGN95l-","executionInfo":{"status":"error","timestamp":1652101668307,"user_tz":-120,"elapsed":1144,"user":{"displayName":"tijl coenen","userId":"13526193257448919759"}},"outputId":"5a58049e-8663-43fe-f841-d4d7ab9f59c2"},"id":"vlb4MiGN95l-","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_18\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_30 (InputLayer)       [(None, 3, 38)]           0         \n","                                                                 \n"," conv1d_36 (Conv1D)          (None, 1, 256)            29440     \n","                                                                 \n"," dropout_73 (Dropout)        (None, 1, 256)            0         \n","                                                                 \n"," conv1d_37 (Conv1D)          (None, 1, 128)            32896     \n","                                                                 \n"," dropout_74 (Dropout)        (None, 1, 128)            0         \n","                                                                 \n"," dense_60 (Dense)            (None, 1, 256)            33024     \n","                                                                 \n"," dropout_75 (Dropout)        (None, 1, 256)            0         \n","                                                                 \n"," dense_61 (Dense)            (None, 1, 256)            65792     \n","                                                                 \n"," dropout_76 (Dropout)        (None, 1, 256)            0         \n","                                                                 \n"," dense_62 (Dense)            (None, 1, 128)            32896     \n","                                                                 \n"," dropout_77 (Dropout)        (None, 1, 128)            0         \n","                                                                 \n"," dense_63 (Dense)            (None, 1, 64)             8256      \n","                                                                 \n"," dense_64 (Dense)            (None, 1, 1)              65        \n","                                                                 \n","=================================================================\n","Total params: 202,369\n","Trainable params: 202,369\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/20\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-87-ff268b7d36b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m           \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weights_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m           )\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 143, in __call__\n        losses, sample_weight, reduction=self._get_reduction())\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/losses_utils.py\", line 322, in compute_weighted_loss\n        losses, None, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/losses_utils.py\", line 211, in squeeze_or_expand_dimensions\n        sample_weight = tf.squeeze(sample_weight, [-1])\n\n    ValueError: Can not squeeze dim[0], expected a dimension of 1, got 32 for '{{node TverskyLoss/weighted_loss/Squeeze}} = Squeeze[T=DT_FLOAT, squeeze_dims=[-1]](Cast)' with input shapes: [32].\n"]}]},{"cell_type":"code","source":["# --------------- CREATE PREDICTIONS FOR IN CLASS SUBMISSIONS ---------------------------\n","\n","# # ---------------- TRANSFORM TEST DATA TO BE IN CORRECT FORMAT FOR LSTM  ------------------------\n","\n","# #LOAD PREPROCESSED DATASETS\n","# #Load dataset month 1\n","# file = open(\"/content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/Test_Data_Cleaned/test_data_robust_1\",\"rb\")\n","# test_df1 = pickle.load(file)\n","# file.close()\n","\n","# test_df1.sort_values(by=['client_id'],inplace=True) #Sort values for consistent row positions per customer across dataframes\n","# client_IDs_X_test_lstm = test_df1['client_id']\n","# test_df1.drop([\"client_id\"],inplace=True,axis=1) #Drop client id\n","# test_df1.reset_index(drop=True,inplace=True)\n","\n","# #Load dataset month 2\n","# file = open(\"/content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/Test_Data_Cleaned/test_data_robust_2\",\"rb\")\n","# test_df2 = pickle.load(file)\n","# file.close()\n","\n","# test_df2.sort_values(by=['client_id'],inplace=True) #Sort values for consistent row positions per customer across dataframes\n","# test_df2.drop([\"client_id\"],inplace=True,axis=1) #Drop client id\n","# test_df2.reset_index(drop=True,inplace=True)\n","\n","# #Load dataset month 3\n","# file = open(\"/content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/Test_Data_Cleaned/test_data_robust_3\",\"rb\")\n","# test_df3 = pickle.load(file)\n","# file.close()\n","\n","# test_df3.sort_values(by=['client_id'],inplace=True) #Sort values for consistent row positions per customer across dataframes\n","# test_df3.drop([\"client_id\"],inplace=True,axis=1) #Drop client id\n","# test_df3.reset_index(drop=True,inplace=True)\n","\n","\n","# #create array to accumulate datasets\n","# X_test_lstm = np.empty((test_df1.shape[0],3,test_df1.shape[1]),dtype='float')\n","# #Add all observations from test_df1\n","# for x in range(len(test_df1)):\n","#   X_test_lstm[x][0] = test_df1.iloc[x,:]\n","#   #Add all observations from test_df2\n","# for x in range(len(test_df2)):\n","#   X_test_lstm[x][1] = test_df2.iloc[x,:]\n","# #Add all observations from test_df3\n","# for x in range(len(test_df3)):\n","#   X_test_lstm[x][2] = test_df3.iloc[x,:]\n","\n","# print(X_test_lstm.shape)\n","\n","# # Pickle the constructed files\n","# file = open(\"/content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/LSTM_DATA/X_test_lstm_robust\",'wb')\n","# pickle.dump(X_test_lstm,file)\n","# file.close()\n","\n","# file = open(\"/content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/LSTM_DATA/client_IDs_X_test_lstm_robust\",'wb')\n","# pickle.dump(np.array(client_IDs_X_test_lstm),file)\n","# file.close()\n","\n","# #Read out test file in format for LSTM\n","# file = open(\"/content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/LSTM_DATA/X_test_lstm_robust\",'rb')\n","# X_test_lstm = pickle.load(file)\n","# file.close()\n","# #Read out the corresponding client IDs\n","# file = open(\"/content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/LSTM_DATA/client_IDs_X_test_lstm_robust\",'rb')\n","# client_IDs_X_test_lstm = pickle.load(file)\n","# file.close()\n","\n","# predictions_proba = np.squeeze(model.predict(X_test_lstm))\n","\n","# #Generate data frame to submit\n","# submission_arr = np.vstack((client_IDs_X_test_lstm,predictions_proba)).T\n","# submission_df = pd.DataFrame(submission_arr)\n","# submission_df = submission_df.rename(columns={0: 'ID', 1: 'PROB'})\n","# print(submission_df.shape, submission_df.head)\n","\n","# #Write submission dataframe to csv\n","# from datetime import date\n","# import time\n","# today = date.today()\n","# today = today.strftime('%y%m%d') \n","# time_now = int(time.time())\n","# suffix = str(today) + '_' + str(time_now)\n","# filepath = \"/content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/submissions/submission_file_LSTM_{}\".format(suffix)\n","# print(\"Path for submission file : {}\".format(filepath))\n","\n","# submission_df.to_csv(filepath,sep=',',header=True,index=False)\n"],"metadata":{"id":"WB8Z97x0hG4L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652101546340,"user_tz":-120,"elapsed":3066,"user":{"displayName":"tijl coenen","userId":"13526193257448919759"}},"outputId":"0fa18259-d830-467f-b73c-abfeeb77d987"},"id":"WB8Z97x0hG4L","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(27300, 2) <bound method NDFrame.head of                                      ID PROB\n","0      00005aaefc4ec95eab088bd07b1ba8c7  0.0\n","1      0000708c331be17d362afbf8ff78401a  0.0\n","2      000270b865873ac669df19a0a1a05950  0.0\n","3      0002754fb482f043f1b0392def2a4ab0  0.0\n","4      00045042cb39e224e80a7bd0388f127e  0.0\n","...                                 ...  ...\n","27295  fffa862e87dc37383f3dfe8f2f7388cf  0.0\n","27296  fffc95ebdc2673e2b23a510faad11cec  0.0\n","27297  fffd91890215fe1476650ef1b60f2b11  1.0\n","27298  fffe766990c6552e78f1bef3c33f7f22  0.0\n","27299  ffff4a236fc06d1c30c6e8b50752f8bf  0.0\n","\n","[27300 rows x 2 columns]>\n","Path for submission file : /content/drive/MyDrive/Studies/Master of AI/Advanced_Analytics/Assignment_1/submissions/submission_file_LSTM_220509_1652101542\n"]}]}],"metadata":{"kernelspec":{"display_name":"tensf","language":"python","name":"tensf"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"LSTM.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}